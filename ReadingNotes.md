# QA Readings
## [Memory Networks][memNet]

  * Training
    * Supervised by giving outputs for max function in 'O' and 'R'
    * Train embedding matrices using SGD and margin loss ranking

## [End-to-End Memory Networks][EToEMemNet]

### [**Source Code][EToEMemNetSource]

## [Towards AI-Complete QA: A set of Prerequisite Toy Tasks][toyTasks]

  * Dataset is self contained.
  * Tasks come with both training and evaluation data
  * These tasks can be generated by source code found [here](https://research.facebook.com/research/babi/)

## [Large-scale Simple QA with Memory Networks][largeScale]

  * Training on multiple datasets had no negative results. Only improved performance
  * Datasets:
    * [Freebase](http://www.freebase.com)
    * [WebQuestions](http://nlp.stanford.edu/software/sempre/)
    * [Reverb](reverb.cs.washing.edu)
      * This site includes source code
    * [SimpleQuestions](https://research.facebook.com/research/babi)
      * New dataset contributed by this paper

## [Ask Me Anything: Dynamic Memory Networking for NLP][AMA]

  * Datasets
    * Used the [toy tasks](https://research.facebook.com/research/babi/) mentioned above
  * Concluded that Dynamic Memory Networks did well for general NLP structure

## [Key-Value Memory Networks for Directly Reading Documents][Key-Value]

  * New approach of Key-Value MemNetworks made reading documents more viable
  * Datasets:
    * [MovieQA](https://research.facebook.com/research/babi/) ~ 100k questions in movie domain
    * Knowledge Base formed from data available on [OmbdApi](http://omdbapi.com/)

## [Semantic Parsing via Staged Query Graph Generation][semanticGraph]

  * Datasets
    * [WebQuestions](http://nlp.stanford.edu/software/sempre/) mentioned above
  * Evaluated results with the [SEMPRE](http://www-nlp.stanford.edu/software/sempre/)
  * Semantic parsing is reduced to graph query generation, formulated as a staged search problem
  * Leverages KB at an early stage to prune search space

## [The Value of Semantic Parse Labeling for KBQA][semanticValue]

  * Datasets
    * [WebQuestionsSP](https://www.microsoft.com/en-us/download/details.aspx?id=52763)
  * Learning from labeled semantic parses significantly improves overall performance
  * Can obtain semantic parses with high accuracy and at a cost comparable to obtaining just the answers

## [QA with Subgraph Enbeddings][subgraph]
  
  * Datasets
    * Trained with [FreeBase](http://www.freebase.com)
    * Tested on [WebQuestions](http://nlp.stanford.edu/software/sempre/)
  * Very weak performance, peaked at 41.8 F1 score, but the best (so far) with no human interaction.

## [Open QA with Weakly Supervised Embedding Models][openWeak]

  * Databases
    * [DBPedia](http://wiki.dbpedia.org/)
    * [WebQuestions](http://nlp.stanford.edu/software/sempre/)
  * Learn to map questions to vectorial feature representations
    * Allows use of any KB without a required lexicon or grammar
  * All variations greatly improved upon [Paralex](http://www.aclweb.org/anthology/P13-1158)

[//]: # (These are reference links used in the body of this note and get stripped out when the markdown processor does its job. There is no need to format nicely because it shouldn't be seen. Thanks SO - http://stackoverflow.com/questions/4823468/store-comments-in-markdown-syntax)

   [memNet]: <http://arxiv.org/pdf/1410.3916v11.pdf>
   [EToEMemNet]: <http://arxiv.org/pdf/1503.08895v5.pdf>
   [EToEMemNetSource]: <https://github.com/facebook/MemNN>
   [toyTasks]: <http://arxiv.org/pdf/1502.05698v10.pdf>
   [largeScale]: <https://arxiv.org/pdf/1506.02075v1.pdf>
   [AMA]: <http://arxiv.org/pdf/1506.07285v5.pdf>
   [Key-Value]: <https://arxiv.org/pdf/1606.03126v1.pdf>
   [semanticGraph]: <https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/ACL15-STAGG.pdf>
   [semanticValue]: <https://www.microsoft.com/en-us/research/wp-content/uploads/2016/08/acl2016-webqsp.pdf>
   [subgraph]: <https://arxiv.org/pdf/1406.3676v3.pdf>
   [openWeak]: <https://arxiv.org/pdf/1404.4326.pdfar>

